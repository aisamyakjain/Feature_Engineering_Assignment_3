{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729b202e-6693-4a12-b34f-a83e7a259f14",
   "metadata": {},
   "source": [
    "Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you \n",
    "might choose one over the other\n",
    "\n",
    "Answer: Ordinal Encoding and Label Encoding are both techniques used to convert categorical variables into numerical representations.\n",
    "\n",
    "Ordinal Encoding assigns unique integers to each category based on their order or rank, whereas Label Encoding assigns a unique integer to each category without considering any specific order.\n",
    "\n",
    "When dealing with categorical variables that have an inherent order or rank, such as education levels (e.g., \"High School,\" \"Bachelor's,\" \"Master's\"), Ordinal Encoding is preferred. On the other hand, if there is no meaningful order among the categories, such as colors (e.g., \"Red,\" \"Blue,\" \"Green\"), Label Encoding is more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e1af8-226f-42d4-9f9d-605282343630",
   "metadata": {},
   "source": [
    "Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in \n",
    "a machine learning project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796d3314-b173-422f-9d14-48937c1a76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'city' : ['New york' , 'London' ,'Paris' , 'Tokyo' , 'New york' , 'Paris'],\n",
    "    'price' : [200 ,150,300,250,180,320]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54168026-bc57-4cdc-8971-31d41874831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New york</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New york</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paris</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  price\n",
       "0  New york    200\n",
       "1    London    150\n",
       "2     Paris    300\n",
       "3     Tokyo    250\n",
       "4  New york    180\n",
       "5     Paris    320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34eb5a96-0ba9-4962-b9d3-d54343edd2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean price of each city\n",
    "\n",
    "mean_price = df.groupby('city')['price'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c4e505-79c4-4486-8ccb-6c4b6fdcbcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'London': 150.0, 'New york': 190.0, 'Paris': 310.0, 'Tokyo': 250.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a6a556-aec2-452c-99a6-f5d98f932fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace each city with its mean\n",
    "\n",
    "df['city encoded'] = df['city'].map(mean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b14659-b839-4986-bd52-1f17b40d7d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>city encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New york</td>\n",
       "      <td>200</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>150</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paris</td>\n",
       "      <td>300</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>250</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New york</td>\n",
       "      <td>180</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paris</td>\n",
       "      <td>320</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  price  city encoded\n",
       "0  New york    200         190.0\n",
       "1    London    150         150.0\n",
       "2     Paris    300         310.0\n",
       "3     Tokyo    250         250.0\n",
       "4  New york    180         190.0\n",
       "5     Paris    320         310.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a419eb7-e88c-4083-b0fb-0628254e5ec9",
   "metadata": {},
   "source": [
    "Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
    "\n",
    "Answer: Covariance is a measure of the relationship between two random variables. It indicates the extent to which the variables change together. Covariance is crucial in statistical analysis as it helps identify the direction (positive or negative) and strength of the linear relationship between variables. It is calculated by averaging the product of the deviations of paired observations from their means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca563347-c5cf-4eb6-b8f3-42153cd981ee",
   "metadata": {},
   "source": [
    "Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, \n",
    "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. \n",
    "Show your code and explain the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebd730a-3756-4263-ad34-67cabf8e35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272b766c-91a7-469d-9339-242eb562061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame({\n",
    "    'Color': ['red', 'green', 'blue'], \n",
    "    'Size':  ['small', 'medium', 'large'], \n",
    "    'Material' : ['wood', 'metal', 'plastic']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0389913-3422-4d13-aad5-e0b07cf5629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>small</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>medium</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>large</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color    Size Material\n",
       "0    red   small     wood\n",
       "1  green  medium    metal\n",
       "2   blue   large  plastic"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f109761-7732-40ca-a0dd-290955872387",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f130a2-91bf-4b52-b79e-8504b30e6405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dfc324b-2596-4bb4-90d9-dc852cca5560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.fit_transform(df['Color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1181f44-19ee-4e45-9ad3-aa834eaf1547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.fit_transform(df['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be453003-51ba-4997-8d17-3ef7aac591d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.fit_transform(df['Material'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de716127-b475-4d42-bcd4-f65dd54536c0",
   "metadata": {},
   "source": [
    "Q6. You are working on a machine learning project with a dataset containing several categorical \n",
    "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), \n",
    "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for \n",
    "each variable, and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b70d493-d48b-4374-ba6f-75117a42b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca21bdc8-6eaa-4936-866a-42a384a0a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Education Level' : ['High School', 'Bachelors' , 'Masters' ], \n",
    "    'Employment Status' : ['Unemployed'  , 'Part-Time' , 'Full-Time']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce138a6b-e47f-4841-bd2e-76e3cc1e3f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Employment Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High School</td>\n",
       "      <td>Unemployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Part-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masters</td>\n",
       "      <td>Full-Time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Education Level Employment Status\n",
       "0     High School        Unemployed\n",
       "1       Bachelors         Part-Time\n",
       "2         Masters         Full-Time"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e89d64-0305-4414-a02c-ad4ebcddf806",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = OrdinalEncoder(categories = [['High School','Bachelors','Masters']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b8cb430-8c1c-482d-965b-39f47a1ea14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.fit_transform(df[['Education Level']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c657f5-aab6-41e5-9bd6-90d9a5cdcb84",
   "metadata": {},
   "source": [
    "Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education \n",
    "level. Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb7872-6277-44a6-b88f-bec5bf0acae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(np.random.randn(1000, 3),\n",
    "                   columns=['Age', 'Income', 'Education'])\n",
    "df.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd97bad-630d-45a0-9776-a6e81a975031",
   "metadata": {},
   "source": [
    "Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two \n",
    "categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\n",
    "East/West). Calculate the covariance between each pair of variables and interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99a67cc-41c4-4534-913e-a0aad9200b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix between Temperature and Humidity:\n",
      "             Temperature  Humidity\n",
      "Temperature         10.2      -5.0\n",
      "Humidity            -5.0      62.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(covariance_matrix)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate the covariance between Temperature and Weather Condition\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m covariance_temp_weather \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeather Condition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print the covariance between Temperature and Weather Condition\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCovariance between Temperature and Weather Condition:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:2814\u001b[0m, in \u001b[0;36mSeries.cov\u001b[0;34m(self, other, min_periods, ddof)\u001b[0m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(this) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m-> 2814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnancov\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1609\u001b[0m, in \u001b[0;36mnancov\u001b[0;34m(a, b, min_periods, ddof)\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a) \u001b[38;5;241m<\u001b[39m min_periods:\n\u001b[1;32m   1607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m-> 1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2680\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2677\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[0;32m-> 2680\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2683\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:518\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    515\u001b[0m     keepdims_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims}\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeepdims_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:182\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    180\u001b[0m ret \u001b[38;5;241m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your dataset in a pandas DataFrame\n",
    "dataset = pd.DataFrame({\n",
    "    'Temperature': [25, 28, 20, 22, 26],\n",
    "    'Humidity': [60, 65, 70, 75, 80],\n",
    "    'Weather Condition': ['Sunny', 'Cloudy', 'Rainy', 'Cloudy', 'Sunny'],\n",
    "    'Wind Direction': ['North', 'South', 'East', 'West', 'North']\n",
    "})\n",
    "\n",
    "# Calculate the covariance matrix using pandas cov() function\n",
    "covariance_matrix = dataset[['Temperature', 'Humidity']].cov()\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(\"Covariance matrix between Temperature and Humidity:\")\n",
    "print(covariance_matrix)\n",
    "\n",
    "# Calculate the covariance between Temperature and Weather Condition\n",
    "covariance_temp_weather = dataset['Temperature'].cov(dataset['Weather Condition'])\n",
    "\n",
    "# Print the covariance between Temperature and Weather Condition\n",
    "print(\"\\nCovariance between Temperature and Weather Condition:\")\n",
    "print(covariance_temp_weather)\n",
    "\n",
    "# Calculate the covariance between Temperature and Wind Direction\n",
    "covariance_temp_wind = dataset['Temperature'].cov(dataset['Wind Direction'])\n",
    "\n",
    "# Print the covariance between Temperature and Wind Direction\n",
    "print(\"\\nCovariance between Temperature and Wind Direction:\")\n",
    "print(covariance_temp_wind)\n",
    "\n",
    "# Calculate the covariance between Humidity and Weather Condition\n",
    "covariance_humidity_weather = dataset['Humidity'].cov(dataset['Weather Condition'])\n",
    "\n",
    "# Print the covariance between Humidity and Weather Condition\n",
    "print(\"\\nCovariance between Humidity and Weather Condition:\")\n",
    "print(covariance_humidity_weather)\n",
    "\n",
    "# Calculate the covariance between Humidity and Wind Direction\n",
    "covariance_humidity_wind = dataset['Humidity'].cov(dataset['Wind Direction'])\n",
    "\n",
    "# Print the covariance between Humidity and Wind Direction\n",
    "print(\"\\nCovariance between Humidity and Wind Direction:\")\n",
    "print(covariance_humidity_wind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb219057-0181-4ca0-99a0-b5e5d6d6aae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
